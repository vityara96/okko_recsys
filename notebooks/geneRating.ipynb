{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import  pyspark.sql.functions as F\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import ArrayType, IntegerType, StructType, StructField, StringType\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_data_path = \"../data/transactions.csv\"\n",
    "catalogue_path = \"../data/catalogue.json\"\n",
    "test_path = \"../data/test_users.json\"\n",
    "ratings_path = \"../data/ratings.csv\"\n",
    "bookmarks_path = \"../data/bookmarks.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "            .appName(\"geneRating\") \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bookmarks exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_df = spark.read.csv(bookmarks_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_df = bm_df.withColumn(\"bookmark\", F.lit(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные по транзакциям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df = spark.read.csv(transactions_data_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем каталог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(catalogue_path, \"r\") as f:\n",
    "    cat_df = json.load(f)\n",
    "\n",
    "cat_df = pd.DataFrame.from_dict(cat_df, orient='index')\n",
    "\n",
    "cat_df = cat_df.reset_index()\n",
    "\n",
    "cat_df.columns = ['element_uid'] + list(cat_df.columns[1:])\n",
    "\n",
    "cat_df.element_uid = cat_df.element_uid.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = spark.createDataFrame(cat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляем к транзакциям информацию о фильме и выбрасываем транзакции по фильмам, по которым нет информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать только информацию о типе фильма и о его длительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = catalogue.select(['element_uid', 'type', 'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tr_df.join(catalogue, on='element_uid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что транзакций по неизвестным фильмам нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"watched_time\", F.col(\"watched_time\")/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что 1% представленного каталога имеет длительность фильма = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue.where(catalogue['duration'] == 0).count() / catalogue.count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим эту длительность на 75%й квантиль времени просмотра этих фильмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как неизвестно, сколько частей в многосерийном фильме и сериале, для каждого такого фильма и сериала посчитаем 75-квантиль и возьмем его за длительность фильма/сериала. Предварительно переведем длительность просмотра в минуты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = df.filter((df['type'] == \"multipart_movie\") | (df['type'] == \"series\") | (df['duration'] == 0))\\\n",
    "    .groupBy('element_uid').agg(F.expr(\"percentile_approx(watched_time, 0.75)\").alias('true_duration'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(quantiles, on=\"element_uid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"true_duration\", F.coalesce(\"true_duration\", \"duration\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим колонку с информацией о том, какую часть фильма посмотрел пользователь, предварительно удалив записи, по которым неизвестна длительность просмотра (около 100к)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where(df['watched_time'].isNotNull())\\\n",
    "    .withColumn(\"watch_part\", F.col('watched_time') / F.col('true_duration'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какую часть всех фильмов составляют фильмы с watch_part > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiwatch_films = df.where((df['type'] == 'movie') & (df['watch_part'] > 1))\n",
    "films = df.where(df['type'] == 'movie')\n",
    "\n",
    "print(f\"Multiwatch films are {multiwatch_films.count()/films.count() * 100} perc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем, что если длительность просмотра > 1,то пользователь просмотрел фильм/сериал несколько раз. Пока не будем это учитывать и заменим зачение на 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"true_watch_part\", F.when(df['watch_part'] > 1, 1).otherwise(F.col(\"watch_part\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#запись в файл\n",
    "\n",
    "df.select(['element_uid', 'user_uid', 'consumption_mode', 'ts', 'device_type', 'device_manufacturer', 'type',\n",
    "          'true_duration', 'true_watch_part'])\\\n",
    "    .repartition(100)\\\n",
    "    .write.parquet(\"../data/ratings_prq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.csv(ratings_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(ratings_df.select(['user_uid', 'element_uid', 'rating']),\n",
    "             on=['user_uid', 'element_uid'], how='left')\\\n",
    "        .join(bm_df.select(['user_uid', 'element_uid', 'bookmark']),\n",
    "             on=['user_uid', 'element_uid'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=[\"bookmark\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select([\n",
    "    'user_uid',\n",
    "    'element_uid',\n",
    "    'consumption_mode',\n",
    "    'ts',\n",
    "    'type',\n",
    "    'true_duration',\n",
    "    'true_watch_part',\n",
    "    'rating',\n",
    "    'bookmark'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
